{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Telecom Customer Churn (Binary Classification).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMMlu7McLkIAP8Cr9cuteJV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fbadine/dl-tutorials/blob/master/Telecom_Customer_Churn_(Binary_Classification).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRXZQPZR9_Vp",
        "colab_type": "text"
      },
      "source": [
        "# Configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ommZM22bRK1C",
        "colab_type": "text"
      },
      "source": [
        "## Include"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBJA6lIVQ-x0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import time\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler, MaxAbsScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score, roc_curve, auc, precision_recall_curve\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "import tensorflow as tf\n",
        "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
        "\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import AUC, FalseNegatives, FalsePositives, TrueNegatives, TruePositives, Recall, Precision\n",
        "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
        "\n",
        "np.random.seed(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWsZnRodQzJs",
        "colab_type": "text"
      },
      "source": [
        "## Initialisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHElMnlaRT8J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init = {\n",
        "    \"datadir\": \"./\",\n",
        "    \"datafile\": \"WA_Fn-UseC_-Telco-Customer-Churn.csv\",\n",
        "    \"test_split\": 0.1,\n",
        "    \"test_random_state\": 42,\n",
        "    \"val_split\": 0.1,\n",
        "    \"val_random_state\": 43,\n",
        "    \"clear_logs\": True,\n",
        "    \"classweights\": True,\n",
        "    \"batchsize\": 32\n",
        "}\n",
        "\n",
        "root_logdir = os.path.join(os.path.curdir, \"logs\")\n",
        "print(\"Root logdir: {}\".format(root_logdir))\n",
        "\n",
        "def get_run_logdir():\n",
        "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
        "    return os.path.join(root_logdir, run_id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNvVUU9zLeLb",
        "colab_type": "text"
      },
      "source": [
        "## Data Location Initialisation\n",
        "\n",
        "You can select 2 types of datasource:\n",
        "* Either you connect to Kaggle and download the dataset from there. For this you will need you Kaggle username and key that you can generate as described [here](https://stackoverflow.com/questions/49310470/using-kaggle-datasets-in-google-colab)\n",
        "* Have the dataset file locally"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdXDTDG9LhJ4",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title Select Dataset Source\n",
        "#@titl \n",
        "\n",
        "import json\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# Create an output if it does not exist or clear it if it exists\n",
        "try:\n",
        "    out.clear_output()\n",
        "except NameError:\n",
        "    out = widgets.Output(layout={'border': '1px solid black'})\n",
        "\n",
        "# Dropdown menu to select the location of the dataset\n",
        "dataset_source = widgets.Dropdown(\n",
        "    options=['--Select--', 'Download from Kaggle', 'Available Locally'],\n",
        "    value='--Select--',\n",
        "    description='Dataset:',\n",
        "    disabled=False,\n",
        ")\n",
        "\n",
        "# Kaggle token username in case the dataset_source is equal to \"Download from Kaggle\"\n",
        "kaggle_user = widgets.Text(\n",
        "    value='',\n",
        "    placeholder='Kaggle token username',\n",
        "    description='Username:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "# Kaggle token key in case the dataset_source is equal to \"Download from Kaggle\"\n",
        "kaggle_key = widgets.Password(\n",
        "    value = '',\n",
        "    placeholder = 'Kaggle token key',\n",
        "    description = 'Key:',\n",
        "    disabled = False\n",
        ")\n",
        "\n",
        "# The local path of the dataset in case the dataset_source is \"Available Locally\"\n",
        "dataset_local_path = widgets.Text(\n",
        "    value='',\n",
        "    placeholder='Dataset location full path',\n",
        "    description='Path:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "#\n",
        "# When the value of datasource changes, this function is called which does the following:\n",
        "# - Clear the previous output\n",
        "# - Based on the new value display the corresponding elements\n",
        "#\n",
        "def on_change(change):\n",
        "    with out:\n",
        "        if change['type'] == 'change' and change['name'] == 'value':\n",
        "            out.clear_output()\n",
        "            if change['new'] == \"Download from Kaggle\":\n",
        "                display(kaggle_user, kaggle_key)\n",
        "            elif change['new'] == \"Available Locally\":\n",
        "                display(dataset_local_path)\n",
        "\n",
        "display(dataset_source, out)\n",
        "\n",
        "dataset_source.observe(on_change)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfbBO14QL61l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if dataset_source.value == \"Download from Kaggle\":\n",
        "  # Installing kaggle\n",
        "  !pip install kaggle\n",
        "\n",
        "  # Creating .kaggle if necessary\n",
        "  !if [ -d .kaggle ]; then echo \".kaggle exists\"; else echo \".kaggle does not exist ... Creating it\"; mkdir .kaggle; if [ -d .kaggle ]; then echo \"Successfully created\"; else echo \"Error creating .kaggle\"; fi; fi\n",
        "\n",
        "  with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "      json.dump(token, file)\n",
        "\n",
        "  # Creating .kaggle if necessary\n",
        "  !if [ -d  ~/.kaggle ]; then echo \" ~/.kaggle exists\"; else echo \" ~/.kaggle does not exist ... Creating it\"; mkdir  ~/.kaggle; if [ -d  ~/.kaggle ]; then echo \"Successfully created\"; else echo \"Error creating  ~/.kaggle\"; fi; fi\n",
        "  !cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
        "\n",
        "  # kaggle configuration\n",
        "  !kaggle config set -n path -v{/content}\n",
        "\n",
        "  # Changing mode\n",
        "  !chmod 600 /root/.kaggle/kaggle.json\n",
        "\n",
        "elif dataset_source.value == \"Available Locally\":\n",
        "    init[\"datadir\"], init[\"datafile\"] = os.path.split(dataset_local_path.value)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdPOLbjZaqwu",
        "colab_type": "text"
      },
      "source": [
        "## Colab Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N453_PXl7DIj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    from google.colab import files, drive\n",
        "\n",
        "    # Install and Configure Kaggle\n",
        "    import json\n",
        "\n",
        "    token = {\n",
        "        \"username\":kaggle_user.value,\n",
        "        \"key\":kaggle_key.value\n",
        "    }\n",
        "except Exception:\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxBIUDw29e7w",
        "colab_type": "text"
      },
      "source": [
        "## Userful Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0K2wVZ5b84Pe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_telco_churn_data(dataset_path, dataset_file):\n",
        "    assert(dataset_path is not None and dataset_file is not None)\n",
        "    \n",
        "    csv_path = os.path.join(dataset_path, dataset_file)\n",
        "    \n",
        "    return pd.read_csv(csv_path)\n",
        "\n",
        "def plot_feature(df,\n",
        "                  x,\n",
        "                  y = \"Percent\",\n",
        "                  title = None,\n",
        "                  x_label = None,\n",
        "                  y_label = None,\n",
        "                  x_axis_split = None,\n",
        "                  figsize=(16,5),\n",
        "                  annotate = False,\n",
        "                  sort_per_feature = True,\n",
        "                  exclude_values = None):\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "\n",
        "    if exclude_values is not None and isinstance(exclude_values, str):\n",
        "        feature_counts = (df.loc[df[x] != exclude_values].groupby(['Churn'])[x]\n",
        "                        .value_counts(normalize=True)\n",
        "                        .rename(y)\n",
        "                        .mul(100)\n",
        "                        .reset_index())\n",
        "    else:\n",
        "        feature_counts = (df.groupby(['Churn'])[x]\n",
        "                        .value_counts(normalize=True)\n",
        "                        .rename(y)\n",
        "                        .mul(100)\n",
        "                        .reset_index())\n",
        "        \n",
        "    if sort_per_feature is True:\n",
        "        feature_counts = feature_counts.sort_values(x, ascending=False)\n",
        "    \n",
        "    p = sns.barplot(x=x, y=y, hue=\"Churn\", data=feature_counts)\n",
        "    if title is not None:\n",
        "        p.set_title(title, fontsize=20)\n",
        "    if x_label is not None:\n",
        "        p.set_xlabel(x_label)\n",
        "    if y_label is not None:\n",
        "        p.set_ylabel(y_label)\n",
        "\n",
        "    if x_axis_split is not None:\n",
        "        _, _ = plt.xticks(np.arange(df[x].min(),\n",
        "                             df[x].max(),\n",
        "                             x_axis_split),\n",
        "                          np.arange(df[x].min(),\n",
        "                             df[x].max(),\n",
        "                             x_axis_split))\n",
        "    if annotate is True:\n",
        "        sizes = []\n",
        "        for patch in p.patches:\n",
        "            h, w = patch.get_height(), patch.get_width()\n",
        "            sizes.append(h)\n",
        "\n",
        "            p.annotate(format(h, '.2f'),\n",
        "                       (patch.get_x() + w / 2., h),\n",
        "                       ha = 'center',\n",
        "                       va = 'center',\n",
        "                       xytext = (0, 10),\n",
        "                       textcoords = 'offset points')\n",
        "            \n",
        "        p.set_ylim(0, max(sizes) * 1.15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOsK7nTL9mpJ",
        "colab_type": "text"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxsR79Eu-3E7",
        "colab_type": "text"
      },
      "source": [
        "## Downloading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcosQulV6RnT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if os.path.exists(init[\"datafile\"]) is False:\n",
        "    if dataset_source.value == \"Download from Kaggle\":\n",
        "        try:\n",
        "            !kaggle datasets download --unzip blastchar/telco-customer-churn -p /content \n",
        "        except:\n",
        "            print(\"Error downloading {}\".format(init[\"datafile\"]))\n",
        "    else:\n",
        "        print(\"{} not found locally!!\".format(init[\"datafile\"]))\n",
        "else:\n",
        "    print(\"{} already exists\".format(init[\"datafile\"]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFVuYyE09j05",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls -l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqwU9nB-_TMD",
        "colab_type": "text"
      },
      "source": [
        "## Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGGlLG8F_XJ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reading the dataset and printing its header\n",
        "df_data = load_telco_churn_data(init[\"datadir\"], init[\"datafile\"])\n",
        "print(\"Data dimension: {}\".format(df_data.shape))\n",
        "\n",
        "# Create a train / test split\n",
        "df_train, df_test = train_test_split(df_data,\n",
        "                                       test_size=init[\"test_split\"],\n",
        "                                       random_state=init[\"test_random_state\"])\n",
        "\n",
        "# Copy in order not to have a warning when trying to alter the data\n",
        "df_train = df_train.copy()\n",
        "df_test  = df_test.copy()\n",
        "\n",
        "print(\"Train Data dimension: {}\".format(df_train.shape))\n",
        "print(\"Test Data dimension: {}\".format(df_test.shape))\n",
        "df_train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WV5Uvf7sAAAu",
        "colab_type": "text"
      },
      "source": [
        "## Data Analysis\n",
        "\n",
        "In this section, we shall explore the data and focus on the following:\n",
        "* General data analysis: \n",
        "    * How many samples do we have for training and testing\n",
        "    * What are the different columns and their types\n",
        "    * Any missing data\n",
        "* Data visualisation: Display the Churn as a function of other properties"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOLxDaJPAnBw",
        "colab_type": "text"
      },
      "source": [
        "### Basic Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-JmRYac0Ygr",
        "colab_type": "text"
      },
      "source": [
        "Let's first see how the training sample is split across churn vs non-churn just to see if we have an unbalanced dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoNg-enoKfFS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "no_yes_percentage = df_train[\"Churn\"].value_counts() / df_train.shape[0] * 100\n",
        "\n",
        "print(\"In the training set, {0:.2f}% will churn and {1:.2f}% will not\".format(no_yes_percentage[1], no_yes_percentage[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dA23rJ2R1B9k",
        "colab_type": "text"
      },
      "source": [
        "It is an unbalanced dataset so we need to take this into consideration when we train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaekC0rq_p2I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(df_train.info())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZIi6E1lAuH_",
        "colab_type": "text"
      },
      "source": [
        "We notice that non of the fields have a null-object. Let's double check this"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9s2PWKjAHLV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(df_train.isnull().sum())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcG-sdDqBAQk",
        "colab_type": "text"
      },
      "source": [
        "However this does not mean that some values are not the way we want them to be.  \n",
        "Example: we notice that unlike `MonthlyCharges` which is of type `float32`, `TotalCharges` is of type `Object`. Let's see if it contains values that are not `float`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfSS9M5wA9Ps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(df_train[\"TotalCharges\"].to_frame().head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Hi6S4gYC-3g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"There are {} white space occurrences in TotalCharges\".format(df_train[\"TotalCharges\"].str.count(\" \").sum()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lBzZ1ugEMbo",
        "colab_type": "text"
      },
      "source": [
        "We have 11 occurrences of space.   \n",
        "Let's drop those for visualisation reasons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oSPsI2YLwCJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "o_shape = df_train.shape\n",
        "\n",
        "df_train.drop(df_train.loc[df_train[\"TotalCharges\"] == \" \"].index, inplace=True)\n",
        "\n",
        "print(\"Shape has been reduced from {} to {}\".format(o_shape, df_train.shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P54XBHAsEamZ",
        "colab_type": "text"
      },
      "source": [
        "### Churn as a function of\n",
        "\n",
        "In this section, we will plot and analyse the Churn as a function of the different profiles' features in order to better understand what drives Churn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L15xZ-4LSU64",
        "colab_type": "text"
      },
      "source": [
        "#### Gender"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "do1RrYzBSbP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_feature(df_train,\n",
        "              x = \"gender\",\n",
        "              title = \"Churn Percentage / Gender\",\n",
        "              x_label = \"Gender\",\n",
        "              y_label = \"Percentage\",\n",
        "              x_axis_split = None,\n",
        "              annotate = True,\n",
        "              exclude_values = 'test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sX0YPo8-soTN",
        "colab_type": "text"
      },
      "source": [
        "**Observation:** Both Male and Female subscribers churn almost equally. 49.85% of churners are male and 50.15% female."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pbqs8l_gTqAw",
        "colab_type": "text"
      },
      "source": [
        "#### Senior Citizen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLXdPaoFSrQJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_feature(df_train,\n",
        "              x = \"SeniorCitizen\",\n",
        "              title = \"Churn Percentage / Senior Citizen\",\n",
        "              x_label = \"Senior Citizen\",\n",
        "              y_label = \"Percentage\",\n",
        "              x_axis_split = None,\n",
        "              annotate = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-oY_9VJtWFk",
        "colab_type": "text"
      },
      "source": [
        "**Observation:** The majority of those who churn are younger people (74.93%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKLoAHTEWu8g",
        "colab_type": "text"
      },
      "source": [
        "#### Partner & Dependents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcwOAD-AUATw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_feature(df_train,\n",
        "              x = \"Partner\",\n",
        "              title = \"Churn Percentage / Partner\",\n",
        "              x_label = \"Partner\",\n",
        "              y_label = \"Percentage\",\n",
        "              x_axis_split = None,\n",
        "              annotate = True)\n",
        "\n",
        "plot_feature(df_train,\n",
        "              x = \"Dependents\",\n",
        "              title = \"Churn Percentage / Dependents\",\n",
        "              x_label = \"Dependents\",\n",
        "              y_label = \"Percentage\",\n",
        "              x_axis_split = None,\n",
        "              annotate = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ss-mwAYCtqrE",
        "colab_type": "text"
      },
      "source": [
        "**Observation:** The majority of those who churn do not have a partner (63.64%) and with no dependents (82.39%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNVzaSyl36II",
        "colab_type": "text"
      },
      "source": [
        "#### Phone Services"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xd51gYgPW4Zc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_feature(df_train,\n",
        "              x = \"PhoneService\",\n",
        "              title = \"Churn Percentage / Phone Service\",\n",
        "              x_label = \"Phone Service\",\n",
        "              y_label = \"Percentage\",\n",
        "              x_axis_split = None,\n",
        "              annotate = True)\n",
        "\n",
        "plot_feature(df_train,\n",
        "              x = \"MultipleLines\",\n",
        "              title = \"Churn Percentage / Multiple Lines\",\n",
        "              x_label = \"Multiple Lines\",\n",
        "              y_label = \"Percentage\",\n",
        "              x_axis_split = None,\n",
        "              annotate = True,\n",
        "              exclude_values = \"No phone service\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1B4dh-UH4fvw",
        "colab_type": "text"
      },
      "source": [
        "The vast majority of those who churn have phone service (90.69%) out of which almost half have multiple lines (50.23% as opposed to 49.7% who don't)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6E-nVSLB5EqJ",
        "colab_type": "text"
      },
      "source": [
        "#### Internet Services"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DH_tH4v5T3E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_feature(df_train,\n",
        "              x = \"InternetService\",\n",
        "              title = \"Churn Percentage / Internet Service\",\n",
        "              x_label = \"Internet Service\",\n",
        "              y_label = \"Percentage\",\n",
        "              x_axis_split = None,\n",
        "              annotate = True)\n",
        "\n",
        "plot_feature(df_train,\n",
        "              x = \"OnlineSecurity\",\n",
        "              title = \"Churn Percentage / Online Security\",\n",
        "              x_label = \"Online Security\",\n",
        "              y_label = \"Percentage\",\n",
        "              x_axis_split = None,\n",
        "              annotate = True,\n",
        "             exclude_values=\"No internet service\")\n",
        "\n",
        "plot_feature(df_train,\n",
        "              x = \"OnlineBackup\",\n",
        "              title = \"Churn Percentage / Online Backup\",\n",
        "              x_label = \"Online Backup\",\n",
        "              y_label = \"Percentage\",\n",
        "              x_axis_split = None,\n",
        "              annotate = True,\n",
        "             exclude_values=\"No internet service\")\n",
        "\n",
        "plot_feature(df_train,\n",
        "              x = \"DeviceProtection\",\n",
        "              title = \"Churn Percentage / Device Protection\",\n",
        "              x_label = \"Device Protection\",\n",
        "              y_label = \"Percentage\",\n",
        "              x_axis_split = None,\n",
        "              annotate = True,\n",
        "             exclude_values=\"No internet service\")\n",
        "\n",
        "plot_feature(df_train,\n",
        "              x = \"TechSupport\",\n",
        "              title = \"Churn Percentage / Tech Support\",\n",
        "              x_label = \"Tech Support\",\n",
        "              y_label = \"Percentage\",\n",
        "              x_axis_split = None,\n",
        "              annotate = True,\n",
        "             exclude_values=\"No internet service\")\n",
        "\n",
        "plot_feature(df_train,\n",
        "              x = \"StreamingTV\",\n",
        "              title = \"Churn Percentage / Streaming TV\",\n",
        "              x_label = \"Streaming TV\",\n",
        "              y_label = \"Percentage\",\n",
        "              x_axis_split = None,\n",
        "              annotate = True,\n",
        "             exclude_values=\"No internet service\")\n",
        "\n",
        "plot_feature(df_train,\n",
        "              x = \"StreamingMovies\",\n",
        "              title = \"Churn Percentage / Streaming Movies\",\n",
        "              x_label = \"Streaming Movies\",\n",
        "              y_label = \"Percentage\",\n",
        "              x_axis_split = None,\n",
        "              annotate = True,\n",
        "             exclude_values=\"No internet service\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAtc4VJa8W7J",
        "colab_type": "text"
      },
      "source": [
        "**Observation:** It seems that the vast majority of churners have internet service (~ 93%). A big chunk of those have fiber optic (~ 69%)\n",
        "The different internet services that are affecting churn are:\n",
        "* Big impact: Online Security (~ 83%) and Tech Support (~ 82%)\n",
        "* Medium impact: Online Backup (~ 70%) and Device Protection (~ 69%)\n",
        "* Low impact: Streaming TV and Streaming Movies (~ 53% each)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rl35bbXP-RND",
        "colab_type": "text"
      },
      "source": [
        "#### Contract"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msCQxymC94pi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_feature(df_train,\n",
        "              x = \"Contract\",\n",
        "              title = \"Churn Percentage / Contract\",\n",
        "              x_label = \"Contract\",\n",
        "              y_label = \"Percentage\",\n",
        "              x_axis_split = None,\n",
        "              annotate = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OA9ormwB-Vtp",
        "colab_type": "text"
      },
      "source": [
        "**Observation:** Those who churn have shorter contracts. The vast majority (~ 88%) are on month-to-month plans while only ~ 2.5% of churners have a two-year-*contract*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVtW3ez4MKZv",
        "colab_type": "text"
      },
      "source": [
        "#### Tenure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnDAngd9D_cL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_feature(df_train,\n",
        "              x = \"tenure\",\n",
        "              title = \"Churn Percentage / Tenure\",\n",
        "              x_label = \"Tenure (months)\",\n",
        "              y_label = \"Percentage\",\n",
        "              x_axis_split = 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1D1tjkJOD1T",
        "colab_type": "text"
      },
      "source": [
        "**Observation:** The majority of customers who churn have not been with the operator for a long period with almost 20% not exceeding one month"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1_ibfBJMTIS",
        "colab_type": "text"
      },
      "source": [
        "#### Billing Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVEIe7Gp-w3p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_feature(df_train,\n",
        "              x = \"PaperlessBilling\",\n",
        "              title = \"Churn Percentage / Paperless Billing\",\n",
        "              x_label = \"Paperless Billing\",\n",
        "              y_label = \"Percentage\",\n",
        "              x_axis_split = None,\n",
        "              annotate = True)\n",
        "\n",
        "plot_feature(df_train,\n",
        "              x = \"PaymentMethod\",\n",
        "              title = \"Churn Percentage / Payment Method\",\n",
        "              x_label = \"Payment Method\",\n",
        "              y_label = \"Percentage\",\n",
        "              x_axis_split = None,\n",
        "              annotate = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYq0sgbjOpL5",
        "colab_type": "text"
      },
      "source": [
        "**Observation:** Almost 75% of churners use paperless billing. ~ 57% use electronic check"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jj4DFM0FM6Mq",
        "colab_type": "text"
      },
      "source": [
        "#### Monthly Charges"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPOPZJhYGNDw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "col     = \"MonthlyCharges\"\n",
        "sep     = \" \"\n",
        "suf     = \"Ranges\"\n",
        "new_col = col + sep + suf\n",
        "\n",
        "bins    = 30\n",
        "x_min   = df_train[col].min()\n",
        "x_max   = df_train[col].max()\n",
        "x_step  = (x_max - x_min) / bins\n",
        "\n",
        "df_train[new_col] = pd.cut(df_train[col], bins, right=True, labels=False)\n",
        "df_train.loc[:, [new_col]] = ((df_train[new_col] + 1) * x_step + x_min).astype(np.int32)\n",
        "\n",
        "plot_feature(df_train,\n",
        "              x = new_col,\n",
        "              title = \"Churn Percentage / Monthly Charges\",\n",
        "              x_label = \"Monthly Charges Ranges (less than)\",\n",
        "              y_label = \"Percentage\",\n",
        "              x_axis_split = None,\n",
        "              sort_per_feature=False)\n",
        "\n",
        "df_train = df_train.drop(columns=[new_col])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDKaqVwsPXVs",
        "colab_type": "text"
      },
      "source": [
        "**Observation:** The Churn slightly changes as a function of the monthly charges with ~ 5% of churners having a monthly bill of less that 21`$`, ~ 8% have their bill less than 81`$` It then decreases to reach 0.4% for monthly bills in the 118`$` range.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5ulL8E3N6LW",
        "colab_type": "text"
      },
      "source": [
        "#### Total Charges"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPd1hOMQJAJ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "col     = \"TotalCharges\"\n",
        "sep     = \" \"\n",
        "suf     = \"Ranges\"\n",
        "new_col = col + sep + suf\n",
        "\n",
        "df_train[col] = df_train[col].map(lambda x: np.nan if x in [' '] else np.float64(x))\n",
        "\n",
        "bins    = 30\n",
        "x_min   = df_train[col].min()\n",
        "x_max   = df_train[col].max()\n",
        "x_step  = (x_max - x_min) / bins\n",
        "\n",
        "df_train[new_col] = pd.cut(df_train[col], bins, right=True, labels=False)\n",
        "df_train.loc[:, [new_col]] = ((df_train[new_col] + 1) * x_step + x_min).astype(np.int32)\n",
        "\n",
        "plot_feature(df_train,\n",
        "              x = new_col,\n",
        "              title = \"Churn Percentage / Total Charges\",\n",
        "              x_label = \"Total Charges Ranges (less than)\",\n",
        "              y_label = \"Percentage\",\n",
        "              x_axis_split = None,\n",
        "              sort_per_feature=False)\n",
        "\n",
        "df_train = df_train.drop(columns=[new_col])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eN_qLW_xWg0v",
        "colab_type": "text"
      },
      "source": [
        "**Observation:** Total Charges on the other hand takes a different shape where the majority of churners (~ 36%) have their total bill less than 307. This percentage decreases until it reaches 0.07%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e_3DZqLlXKH",
        "colab_type": "text"
      },
      "source": [
        "## Data Preprocessing\n",
        "\n",
        "In this section, we will create pipelines and a column transformer that will prepare the data for training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvAd4j3heho3",
        "colab_type": "text"
      },
      "source": [
        "### Reloading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypsodO4kE0p9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If df_train and df_test were already read, delete them in order\n",
        "# to load them again and let the automatic data preprocessing take\n",
        "# care of the wrong data in TotalAmounts column automatically\n",
        "try:\n",
        "    del df_train\n",
        "    del df_test\n",
        "except NameError:\n",
        "    pass\n",
        "\n",
        "df_data = load_telco_churn_data(init[\"datadir\"], init[\"datafile\"])\n",
        "\n",
        "# Create a (train, val) / test split\n",
        "df_train, df_test = train_test_split(df_data,\n",
        "                                       test_size=init[\"test_split\"],\n",
        "                                       random_state=init[\"test_random_state\"])\n",
        "\n",
        "# Copy in order not to have a warning when trying to alter the data\n",
        "df_train_features = df_train.copy()\n",
        "df_train_labels   = df_train[\"Churn\"].map(dict(Yes=1, No=0)).copy()\n",
        "df_train_features = df_train.drop(\"Churn\", axis=1)\n",
        "\n",
        "df_test_features  = df_test.copy()\n",
        "df_test_labels    = df_test[\"Churn\"].map(dict(Yes=1, No=0)).copy()\n",
        "df_test_features  = df_test.drop(\"Churn\", axis=1)\n",
        "\n",
        "# Remove df_data\n",
        "del df_data, df_train, df_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBrJybx1kPND",
        "colab_type": "text"
      },
      "source": [
        "### Encoders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubJYHlbOZmDC",
        "colab_type": "text"
      },
      "source": [
        "#### Object to Float Encoder\n",
        "This encoder is used to transform the TotalCharges attribute which in the dataset is of type Object and its elements are of type string. 10 of which, as we have seen contains space.\n",
        "We are replacing any value that cannot be converted to np.float64 by a `replace_value` with default value is np.nan\n",
        "When this goes into a Pipeline, a SimpleImputer should follow that will replace np.nan by the appropriate value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHXUiGxukWiU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ObjectToFloatEncoder(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, replace_value = np.nan):\n",
        "        self.replace_value = replace_value\n",
        "    \n",
        "    def fit(self, X, y = None):\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X, y = None):\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            for s_name in list(X):\n",
        "                X[s_name] = X[s_name].map(lambda x: self.replace_value if not self._is_float(x) else np.float64(x))\n",
        "        elif isinstance(X, pd.Series):\n",
        "            X = X.map(lambda x: self.replace_value if not self._is_float(x) else np.float64(x))\n",
        "        else:\n",
        "            X = np.apply_along_axis(self._to_float64, 0, X)\n",
        "        \n",
        "        return X\n",
        "\n",
        "    def _is_float(self, s):\n",
        "        try:\n",
        "            np.float64(s)\n",
        "            return True\n",
        "        except ValueError:\n",
        "            return False\n",
        "\n",
        "    def _to_float64(self, s):\n",
        "        try:\n",
        "            f = np.float64(s)\n",
        "        except ValueError:\n",
        "            f = [np.float64(x) if is_float(x) else self.replace_value for x in s]\n",
        "        \n",
        "        return f\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-euPxAK0HleI",
        "colab_type": "text"
      },
      "source": [
        "### Pipelines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p05bSlwhHqCN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pass_attrs = [\"SeniorCitizen\"]\n",
        "\n",
        "pass_pipeline = Pipeline([\n",
        "    ('pass', \"passthrough\")\n",
        "])\n",
        "\n",
        "ordinal_attrs = [\"gender\", \"Partner\", \"Dependents\", \"PhoneService\", \"PaperlessBilling\"]\n",
        "\n",
        "ordinal_pipeline = Pipeline([\n",
        "    ('ordinal', OrdinalEncoder()),\n",
        "    ('std_scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "onehot_attrs = [\"MultipleLines\", \"InternetService\", \"OnlineSecurity\", \"OnlineBackup\",\n",
        "                \"DeviceProtection\", \"TechSupport\", \"StreamingTV\", \"StreamingMovies\",\n",
        "                \"Contract\", \"PaymentMethod\"]\n",
        "\n",
        "onehot_pipeline = Pipeline([\n",
        "    ('onehot', OneHotEncoder())\n",
        "])\n",
        "\n",
        "total_attrs = [\"TotalCharges\"]\n",
        "\n",
        "total_pipeline = Pipeline([\n",
        "    ('obj_to_float', ObjectToFloatEncoder()),\n",
        "    ('imputer', SimpleImputer(strategy=\"mean\")),\n",
        "    ('std_scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "num_attrs = [\"tenure\", \"MonthlyCharges\"]\n",
        "\n",
        "num_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
        "    ('std_scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "full_pipeline = ColumnTransformer([\n",
        "    (\"pass\", pass_pipeline, pass_attrs),\n",
        "    (\"ordinal\", ordinal_pipeline, ordinal_attrs),\n",
        "    (\"onehot\", onehot_pipeline, onehot_attrs),\n",
        "    (\"total\", total_pipeline, total_attrs),\n",
        "    (\"num\", num_pipeline, num_attrs)\n",
        "], remainder='drop')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJrvF29Aeo9D",
        "colab_type": "text"
      },
      "source": [
        "#### Generating Preprocessed Sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sz1fW0IyXVSs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train_processed = full_pipeline.fit_transform(df_train_features)\n",
        "df_test_processed = full_pipeline.fit_transform(df_test_features)\n",
        "\n",
        "print(\"Dataset dimension transformed from {} to {}\".format(df_train_features.shape[1], df_train_processed.shape[1]))\n",
        "\n",
        "print(\"Training set dimension: {}\".format(df_train_processed.shape))\n",
        "print(\"Test set dimension: {}\".format(df_test_processed.shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5YIyL4xcg5e",
        "colab_type": "text"
      },
      "source": [
        "### Getting Class Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLf-Yyirckw7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "counts = np.bincount(df_train_labels)\n",
        "print(\n",
        "    \"Number of positive samples in training data: {} ({:.2f}% of total)\".format(\n",
        "        counts[1], 100 * float(counts[1]) / df_train_labels.shape[0]\n",
        "    )\n",
        ")\n",
        "\n",
        "class_weights = {0: 1.0 / counts[0], 1: 1.0 / counts[1]}\n",
        "print(class_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgW35ri4_r1F",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmEl7OY2_9Ce",
        "colab_type": "text"
      },
      "source": [
        "## Initialisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tONXZM3YfgAN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBLjEbNNv24q",
        "colab_type": "text"
      },
      "source": [
        "#### TPU Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcBvNrMMv0Ug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TPU detection  \n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "  print(\"Running on TPU \", tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "  tpu = None\n",
        "\n",
        "# TPUStrategy for distributed training\n",
        "if tpu:\n",
        "  tf.config.experimental_connect_to_cluster(tpu)\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "  strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "\n",
        "  init[\"batchsize\"] = 16 * strategy.num_replicas_in_sync\n",
        "  print(\"Batchsize changed to {}\".format(init[\"batchsize\"]))\n",
        "else: # default strategy that works on CPU and single GPU\n",
        "  strategy = tf.distribute.get_strategy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdBMZZDO__-X",
        "colab_type": "text"
      },
      "source": [
        "### Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAA_rPKDADqb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(input_shape, strategy):\n",
        "    with strategy.scope():\n",
        "        # Defining metrics\n",
        "        metrics = [\n",
        "            FalseNegatives(name=\"fn\"),\n",
        "            FalsePositives(name=\"fp\"),\n",
        "            TrueNegatives(name=\"tn\"),\n",
        "            TruePositives(name=\"tp\"),\n",
        "            Precision(name=\"precision\"),\n",
        "            Recall(name=\"recall\"),\n",
        "            AUC(name=\"auc\")\n",
        "        ]\n",
        "\n",
        "        inputs = Input(shape=input_shape, name=\"input\")\n",
        "\n",
        "        x = inputs\n",
        "\n",
        "        x = Dense(20, activation='relu', name=\"dense1\")(x)\n",
        "        x = Dropout(0.2, name=\"dropout1\")(x)\n",
        "        x = Dense(15, activation='relu', name=\"dense2\")(x)\n",
        "        x = Dropout(0.4, name=\"dropout2\")(x)\n",
        "        x = Dense(20, activation='relu', name=\"dense3\")(x)\n",
        "        x = Dropout(0.2, name=\"dropout3\")(x)\n",
        "        x = Dense(25, activation='relu', name=\"dense4\")(x)\n",
        "        x = Dropout(0.3, name=\"dropout4\")(x)\n",
        "\n",
        "        outputs = Dense(1, activation='sigmoid', name=\"output\")(x)\n",
        "\n",
        "        model = Model(inputs, outputs)\n",
        "\n",
        "        model.compile(optimizer=Adam(lr=0.0035157669392935006), # 0.0035157669392935006\n",
        "                                    loss='binary_crossentropy',\n",
        "                                    metrics=metrics)\n",
        "\n",
        "    return model\n",
        "\n",
        "model = build_model(df_train_processed.shape[1:], strategy=strategy)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqviF3oqgcMT",
        "colab_type": "text"
      },
      "source": [
        "### Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYuZiW1Agep9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "earlystopping_cb = EarlyStopping(patience=10, restore_best_weights=True)\n",
        "mdlcheckpoint_cb = ModelCheckpoint(\"model.h5\", monitor=\"val_fn\", save_best_only=True)\n",
        "tensorboard_cb   = TensorBoard(get_run_logdir())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EROvnb4QAcH_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if tpu is not None:\n",
        "    callbacks = [earlystopping_cb, mdlcheckpoint_cb]\n",
        "else:\n",
        "    callbacks = [earlystopping_cb, mdlcheckpoint_cb, tensorboard_cb]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozwWDBzQGHBU",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTfraF74GKgJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time \n",
        "history = model.fit(df_train_processed, df_train_labels, epochs=100, batch_size=init[\"batchsize\"],\n",
        "                validation_split=init[\"val_split\"],\n",
        "                class_weight=class_weights if init[\"classweights\"] is True else None,\n",
        "                callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcPu-SHxgmdR",
        "colab_type": "text"
      },
      "source": [
        "### Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSyxEvRfaSDB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if tpu is None:\n",
        "    %load_ext tensorboard\n",
        "    %tensorboard --logdir={root_logdir} --port=6066"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5z_dECMMgraK",
        "colab_type": "text"
      },
      "source": [
        "### Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xpka3WlOlCvC",
        "colab_type": "text"
      },
      "source": [
        "Due to an issue in EarlyStopping ([Check GitHub issue here](https://github.com/tensorflow/tensorflow/issues/35634)), we are loading the best model that was saved by ModelCheckPoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24GEq34Jlcz-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_model = tf.keras.models.load_model(\"model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUM1WD8u-0pc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(best_model.evaluate(df_test_processed, df_test_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EM6QiFQwZPF",
        "colab_type": "text"
      },
      "source": [
        "We notice the following:\n",
        "* Out of the overall 335 predicted cases that are probably going to churn, only 175 (True Positives) are actually going to churn. A 52% rate. \n",
        "* Out of 191 subscribers that will churn, the system only missed 19 (False Negatives) (a 90% detecting accuracy) \n",
        "\n",
        "It means that our model:\n",
        "* Is able to detect the majority of the cases that will churn\n",
        "* However, when it claims a subscriber is going to churn, it is just 52%\n",
        "\n",
        "**Conclusion:** What is most important for us is to minimise those False Negatives i.e. those who will churn but we failed to predict even if along the way we incorrectly predicted that some customer is going to churn while he won't. "
      ]
    }
  ]
}